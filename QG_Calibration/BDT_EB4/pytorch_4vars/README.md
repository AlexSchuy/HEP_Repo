1. Training1_ex1.ipynb - use the [website](https://www.kaggle.com/code/unstructuredrahul/deep-learning-pytorch-binary-classification) example   
batch_size = n_training_sample   
epoch = 100   
layer  = 10, 5  

2. Training1_ex2.ipynb - use the [website](https://www.kaggle.com/code/unstructuredrahul/deep-learning-pytorch-binary-classification) example      
batch_size = 4511497 (0.1 of training)        
epoch = 100   
layer  = 10, 5  

3. Training1_ex3.ipynb - use the [website](https://www.kaggle.com/code/unstructuredrahul/deep-learning-pytorch-binary-classification) example with higher learning rate
batch_size = n_training_sample   
epoch = 100     
layer  = 10, 5 
learning_rate = 0.01

4. Training1_ex4.ipynb - use the website example but with sklearn MLP config
batch_size = n_training_sample   
epoch = 100     
layer  = 10, 7, 5 
no dropout layer, no batchNorm layer 
use StandardScaler