{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_wine\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import joblib\n",
    "import os, sys \n",
    "sys.path.append('/global/cfs/projectdirs/atlas/hrzhao/HEP_Repo/QG_Calibration/BDT_EB4/LightGBM')\n",
    "from LightGBM_BDT_train import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_full_dataset = 0\n",
    "\n",
    "if use_full_dataset:\n",
    "    sample_path = '/global/cfs/projectdirs/atlas/hrzhao/HEP_Repo/QG_Calibration/BDT_EB4/samples/sample_all_jets.pkl'\n",
    "    output_path = './full_dataset'\n",
    "    n_trails = 100\n",
    "    \n",
    "else:\n",
    "    sample_path = '/global/cfs/projectdirs/atlas/hrzhao/HEP_Repo/QG_Calibration/BDT_EB4/samples/sample_testweight_123'\n",
    "    output_path = \"./small_dataset\"\n",
    "    n_trails = 10\n",
    "# Use for full dataset tuning\n",
    "# sample_path = '/global/cfs/projectdirs/atlas/hrzhao/HEP_Repo/QG_Calibration/BDT_EB4/samples/sample_all_jets.pkl'\n",
    "\n",
    "# Use for code dev with a small dataset \n",
    "\n",
    "output_folder = Path(output_path)\n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "study_output = output_folder / 'study.pkl'\n",
    "gbdt_filename = output_folder / 'lightgbm_gbdt.pkl'\n",
    "eval_result_filename = output_folder / 'eval_result.pkl'\n",
    "\n",
    "training_vars = ['jet_pt', 'jet_nTracks', 'jet_trackWidth', 'jet_trackC1']\n",
    "training_weight = ['flatpt_weight']\n",
    "\n",
    "label_pt_bin = [500, 600, 800, 1000, 1200, 1500, 2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jet_pt</th>\n",
       "      <th>jet_eta</th>\n",
       "      <th>jet_nTracks</th>\n",
       "      <th>jet_trackWidth</th>\n",
       "      <th>jet_trackC1</th>\n",
       "      <th>jet_trackBDT</th>\n",
       "      <th>jet_PartonTruthLabelID</th>\n",
       "      <th>equal_weight</th>\n",
       "      <th>event_weight</th>\n",
       "      <th>flatpt_weight</th>\n",
       "      <th>is_forward</th>\n",
       "      <th>pt_idx</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3040225</th>\n",
       "      <td>1771.308105</td>\n",
       "      <td>-1.185907</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.111155</td>\n",
       "      <td>0.297679</td>\n",
       "      <td>-0.001197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>1.832609e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308762</th>\n",
       "      <td>576.650024</td>\n",
       "      <td>-1.632921</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.030110</td>\n",
       "      <td>0.227651</td>\n",
       "      <td>0.115335</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954678</td>\n",
       "      <td>4.073045e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24589109</th>\n",
       "      <td>549.962463</td>\n",
       "      <td>-0.248085</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.028959</td>\n",
       "      <td>0.142942</td>\n",
       "      <td>-0.211451</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.534956</td>\n",
       "      <td>1.849374e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6893257</th>\n",
       "      <td>926.854065</td>\n",
       "      <td>0.773220</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.022511</td>\n",
       "      <td>0.151775</td>\n",
       "      <td>-0.290329</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130191</td>\n",
       "      <td>7.915768e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729798</th>\n",
       "      <td>1347.683838</td>\n",
       "      <td>-0.424933</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.046835</td>\n",
       "      <td>0.199852</td>\n",
       "      <td>-0.123005</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.039094</td>\n",
       "      <td>3.223083e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               jet_pt   jet_eta  jet_nTracks  jet_trackWidth  jet_trackC1  \\\n",
       "3040225   1771.308105 -1.185907         24.0        0.111155     0.297679   \n",
       "3308762    576.650024 -1.632921         18.0        0.030110     0.227651   \n",
       "24589109   549.962463 -0.248085         12.0        0.028959     0.142942   \n",
       "6893257    926.854065  0.773220         11.0        0.022511     0.151775   \n",
       "729798    1347.683838 -0.424933         20.0        0.046835     0.199852   \n",
       "\n",
       "          jet_trackBDT  jet_PartonTruthLabelID  equal_weight  event_weight  \\\n",
       "3040225      -0.001197                     1.0           1.0      0.002129   \n",
       "3308762       0.115335                    21.0           1.0      0.954678   \n",
       "24589109     -0.211451                     4.0           1.0      0.534956   \n",
       "6893257      -0.290329                     2.0           1.0      0.130191   \n",
       "729798       -0.123005                     2.0           1.0      0.039094   \n",
       "\n",
       "          flatpt_weight  is_forward  pt_idx  target  \n",
       "3040225    1.832609e-06         1.0       5     0.0  \n",
       "3308762    4.073045e-07         1.0       0     1.0  \n",
       "24589109   1.849374e-07         0.0       0     0.0  \n",
       "6893257    7.915768e-07         1.0       2     0.0  \n",
       "729798     3.223083e-06         1.0       4     0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample.iloc[:, :-1]\n",
    "\n",
    "target_idx = sample.columns.get_loc('target')\n",
    "y = sample.iloc[:, target_idx]\n",
    "\n",
    "X_dev,X_test, y_dev,y_test = train_test_split(X, y, test_size=0.1, random_state=456)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.1/0.9, random_state=789)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After test, eval_sample_weight already pass the event weight \n",
    "# def auc_weighted(y_true, y_pred, weight):\n",
    "#     fpr, tpr, thresholds = roc_curve(y_true, y_pred, sample_weight = weight)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     return ('auc_weighted', eval_result, is_higher_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.687298\tvalid_0's auc: 0.809738\n",
      "[2]\tvalid_0's binary_logloss: 0.658713\tvalid_0's auc: 0.815083\n",
      "[3]\tvalid_0's binary_logloss: 0.635221\tvalid_0's auc: 0.816445\n",
      "[4]\tvalid_0's binary_logloss: 0.61627\tvalid_0's auc: 0.817139\n",
      "[5]\tvalid_0's binary_logloss: 0.600877\tvalid_0's auc: 0.818534\n",
      "[6]\tvalid_0's binary_logloss: 0.58712\tvalid_0's auc: 0.819185\n",
      "[7]\tvalid_0's binary_logloss: 0.575876\tvalid_0's auc: 0.819846\n",
      "[8]\tvalid_0's binary_logloss: 0.567007\tvalid_0's auc: 0.8206\n",
      "[9]\tvalid_0's binary_logloss: 0.559179\tvalid_0's auc: 0.821061\n",
      "[10]\tvalid_0's binary_logloss: 0.552635\tvalid_0's auc: 0.821239\n",
      "[11]\tvalid_0's binary_logloss: 0.547141\tvalid_0's auc: 0.822448\n",
      "[12]\tvalid_0's binary_logloss: 0.541907\tvalid_0's auc: 0.823068\n",
      "[13]\tvalid_0's binary_logloss: 0.537786\tvalid_0's auc: 0.823633\n",
      "[14]\tvalid_0's binary_logloss: 0.533981\tvalid_0's auc: 0.823826\n",
      "[15]\tvalid_0's binary_logloss: 0.530847\tvalid_0's auc: 0.824195\n",
      "[16]\tvalid_0's binary_logloss: 0.527931\tvalid_0's auc: 0.824495\n",
      "[17]\tvalid_0's binary_logloss: 0.525568\tvalid_0's auc: 0.824924\n",
      "[18]\tvalid_0's binary_logloss: 0.523542\tvalid_0's auc: 0.825151\n",
      "[19]\tvalid_0's binary_logloss: 0.521713\tvalid_0's auc: 0.825456\n",
      "[20]\tvalid_0's binary_logloss: 0.520074\tvalid_0's auc: 0.825653\n",
      "[21]\tvalid_0's binary_logloss: 0.518761\tvalid_0's auc: 0.825879\n",
      "[22]\tvalid_0's binary_logloss: 0.517494\tvalid_0's auc: 0.826116\n",
      "[23]\tvalid_0's binary_logloss: 0.516517\tvalid_0's auc: 0.826318\n",
      "[24]\tvalid_0's binary_logloss: 0.515582\tvalid_0's auc: 0.826508\n",
      "[25]\tvalid_0's binary_logloss: 0.514714\tvalid_0's auc: 0.826654\n",
      "[26]\tvalid_0's binary_logloss: 0.514017\tvalid_0's auc: 0.826769\n",
      "[27]\tvalid_0's binary_logloss: 0.513269\tvalid_0's auc: 0.826979\n",
      "[28]\tvalid_0's binary_logloss: 0.512613\tvalid_0's auc: 0.827205\n",
      "[29]\tvalid_0's binary_logloss: 0.512139\tvalid_0's auc: 0.8273\n",
      "[30]\tvalid_0's binary_logloss: 0.511741\tvalid_0's auc: 0.827396\n",
      "[31]\tvalid_0's binary_logloss: 0.511364\tvalid_0's auc: 0.827523\n",
      "[32]\tvalid_0's binary_logloss: 0.510945\tvalid_0's auc: 0.827639\n",
      "[33]\tvalid_0's binary_logloss: 0.510653\tvalid_0's auc: 0.8277\n",
      "[34]\tvalid_0's binary_logloss: 0.510373\tvalid_0's auc: 0.827754\n",
      "[35]\tvalid_0's binary_logloss: 0.510126\tvalid_0's auc: 0.82783\n",
      "[36]\tvalid_0's binary_logloss: 0.50981\tvalid_0's auc: 0.827962\n",
      "[37]\tvalid_0's binary_logloss: 0.509537\tvalid_0's auc: 0.828139\n",
      "[38]\tvalid_0's binary_logloss: 0.509295\tvalid_0's auc: 0.828229\n",
      "[39]\tvalid_0's binary_logloss: 0.509066\tvalid_0's auc: 0.828317\n",
      "[40]\tvalid_0's binary_logloss: 0.508891\tvalid_0's auc: 0.828368\n",
      "[41]\tvalid_0's binary_logloss: 0.508694\tvalid_0's auc: 0.828456\n",
      "[42]\tvalid_0's binary_logloss: 0.508547\tvalid_0's auc: 0.828507\n",
      "[43]\tvalid_0's binary_logloss: 0.508334\tvalid_0's auc: 0.828634\n",
      "[44]\tvalid_0's binary_logloss: 0.508181\tvalid_0's auc: 0.828712\n",
      "[45]\tvalid_0's binary_logloss: 0.508093\tvalid_0's auc: 0.828728\n",
      "[46]\tvalid_0's binary_logloss: 0.50802\tvalid_0's auc: 0.828743\n",
      "[47]\tvalid_0's binary_logloss: 0.507857\tvalid_0's auc: 0.828816\n",
      "[48]\tvalid_0's binary_logloss: 0.507713\tvalid_0's auc: 0.828919\n",
      "[49]\tvalid_0's binary_logloss: 0.507623\tvalid_0's auc: 0.828951\n",
      "[50]\tvalid_0's binary_logloss: 0.507571\tvalid_0's auc: 0.828956\n",
      "[51]\tvalid_0's binary_logloss: 0.507459\tvalid_0's auc: 0.829008\n",
      "[52]\tvalid_0's binary_logloss: 0.507356\tvalid_0's auc: 0.829054\n",
      "[53]\tvalid_0's binary_logloss: 0.507269\tvalid_0's auc: 0.829099\n",
      "[54]\tvalid_0's binary_logloss: 0.507201\tvalid_0's auc: 0.829125\n",
      "[55]\tvalid_0's binary_logloss: 0.507062\tvalid_0's auc: 0.829215\n",
      "[56]\tvalid_0's binary_logloss: 0.506918\tvalid_0's auc: 0.829312\n",
      "[57]\tvalid_0's binary_logloss: 0.506821\tvalid_0's auc: 0.829372\n",
      "[58]\tvalid_0's binary_logloss: 0.506758\tvalid_0's auc: 0.829404\n",
      "[59]\tvalid_0's binary_logloss: 0.506717\tvalid_0's auc: 0.829421\n",
      "[60]\tvalid_0's binary_logloss: 0.506694\tvalid_0's auc: 0.829424\n",
      "[61]\tvalid_0's binary_logloss: 0.506588\tvalid_0's auc: 0.829496\n",
      "[62]\tvalid_0's binary_logloss: 0.506479\tvalid_0's auc: 0.829564\n",
      "[63]\tvalid_0's binary_logloss: 0.506453\tvalid_0's auc: 0.829576\n",
      "[64]\tvalid_0's binary_logloss: 0.506405\tvalid_0's auc: 0.829603\n",
      "[65]\tvalid_0's binary_logloss: 0.506399\tvalid_0's auc: 0.829605\n",
      "[66]\tvalid_0's binary_logloss: 0.506308\tvalid_0's auc: 0.829661\n",
      "[67]\tvalid_0's binary_logloss: 0.506243\tvalid_0's auc: 0.829699\n",
      "[68]\tvalid_0's binary_logloss: 0.506239\tvalid_0's auc: 0.8297\n",
      "[69]\tvalid_0's binary_logloss: 0.506149\tvalid_0's auc: 0.829759\n",
      "[70]\tvalid_0's binary_logloss: 0.506136\tvalid_0's auc: 0.829767\n",
      "[71]\tvalid_0's binary_logloss: 0.506065\tvalid_0's auc: 0.82981\n",
      "[72]\tvalid_0's binary_logloss: 0.506042\tvalid_0's auc: 0.829823\n",
      "[73]\tvalid_0's binary_logloss: 0.505989\tvalid_0's auc: 0.829854\n",
      "[74]\tvalid_0's binary_logloss: 0.505952\tvalid_0's auc: 0.829873\n",
      "[75]\tvalid_0's binary_logloss: 0.505946\tvalid_0's auc: 0.829876\n",
      "[76]\tvalid_0's binary_logloss: 0.505881\tvalid_0's auc: 0.829914\n",
      "[77]\tvalid_0's binary_logloss: 0.505855\tvalid_0's auc: 0.829932\n",
      "[78]\tvalid_0's binary_logloss: 0.505842\tvalid_0's auc: 0.82994\n",
      "[79]\tvalid_0's binary_logloss: 0.505784\tvalid_0's auc: 0.829977\n",
      "[80]\tvalid_0's binary_logloss: 0.50578\tvalid_0's auc: 0.829978\n",
      "[81]\tvalid_0's binary_logloss: 0.505756\tvalid_0's auc: 0.829993\n",
      "[82]\tvalid_0's binary_logloss: 0.50573\tvalid_0's auc: 0.830011\n",
      "[83]\tvalid_0's binary_logloss: 0.505706\tvalid_0's auc: 0.830026\n",
      "[84]\tvalid_0's binary_logloss: 0.505692\tvalid_0's auc: 0.830036\n",
      "[85]\tvalid_0's binary_logloss: 0.505667\tvalid_0's auc: 0.83005\n",
      "[86]\tvalid_0's binary_logloss: 0.505606\tvalid_0's auc: 0.830089\n",
      "[87]\tvalid_0's binary_logloss: 0.505593\tvalid_0's auc: 0.830097\n",
      "[88]\tvalid_0's binary_logloss: 0.505547\tvalid_0's auc: 0.830125\n",
      "[89]\tvalid_0's binary_logloss: 0.505521\tvalid_0's auc: 0.830142\n",
      "[90]\tvalid_0's binary_logloss: 0.505516\tvalid_0's auc: 0.830144\n",
      "[91]\tvalid_0's binary_logloss: 0.505475\tvalid_0's auc: 0.830168\n",
      "[92]\tvalid_0's binary_logloss: 0.505473\tvalid_0's auc: 0.83017\n",
      "[93]\tvalid_0's binary_logloss: 0.505428\tvalid_0's auc: 0.830198\n",
      "[94]\tvalid_0's binary_logloss: 0.505428\tvalid_0's auc: 0.830198\n",
      "[95]\tvalid_0's binary_logloss: 0.505415\tvalid_0's auc: 0.830206\n",
      "[96]\tvalid_0's binary_logloss: 0.505405\tvalid_0's auc: 0.830212\n",
      "[97]\tvalid_0's binary_logloss: 0.505389\tvalid_0's auc: 0.830223\n",
      "[98]\tvalid_0's binary_logloss: 0.505367\tvalid_0's auc: 0.830236\n",
      "[99]\tvalid_0's binary_logloss: 0.505329\tvalid_0's auc: 0.83026\n",
      "[100]\tvalid_0's binary_logloss: 0.505323\tvalid_0's auc: 0.830264\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Train a base model with default setting. Only set random_state for reproducibility. \n",
    "base_model = lgb.LGBMClassifier(random_state=42)\n",
    "# base_model.fit(X_train[training_vars], y_train, sample_weight=X_train[training_weight].to_numpy().flatten())\n",
    "base_model.fit(X = X_train[training_vars], y = y_train, sample_weight=X_train[training_weight].to_numpy().flatten(),\n",
    "               eval_set = [(X_val[training_vars], y_val)], eval_sample_weight = [X_val[\"event_weight\"].to_numpy().flatten()],\n",
    "               eval_metric = ['binary_logloss', 'auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.79      0.78    283334\n",
      "         1.0       0.72      0.71      0.71    216666\n",
      "\n",
      "    accuracy                           0.75    500000\n",
      "   macro avg       0.75      0.75      0.75    500000\n",
      "weighted avg       0.75      0.75      0.75    500000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = base_model.predict(X_test[training_vars])\n",
    "accuracy_score(y_test, y_test_pred)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_decisions = base_model.predict(X_train[training_vars], raw_score = True)\n",
    "y_test_decisions = base_model.predict(X_test[training_vars], raw_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_func(X_test, y_test_decisions, y_test, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(y_decisions=y_test_decisions, y_tmva=X_test.iloc[:,X_test.columns.get_loc('jet_trackBDT')], \n",
    "                 y_ntrk=X_test.iloc[:,X_test.columns.get_loc('jet_nTracks')], target=y_test, \n",
    "                 X_weight=X_test['event_weight'], features=\" 4 vars\", output_path=output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overtraining_validation(X_dev=X_train, X_test=X_test, y_dev=y_train, y_test=y_test, \n",
    "                                    y_dev_decisions=y_train_decisions, y_test_decisions=y_test_decisions, \n",
    "                                    output_path=output_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function to be minimized.\n",
    "    \"\"\"\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    # TODO Add a pruner to observe intermediate results and stop unpromising trials.\n",
    "    # https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_integration.py \n",
    "    # https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/003_efficient_optimization_algorithms.html\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    \n",
    "    gbm = lgb.LGBMClassifier(**param)\n",
    "    # gbm.fit(X = X_train[training_vars], y = y_train, sample_weight=X_train[training_weight].to_numpy().flatten())\n",
    "    gbm.fit(X = X_train[training_vars], y = y_train, sample_weight=X_train[training_weight].to_numpy().flatten(),\n",
    "            eval_set = [(X_val[training_vars], y_val)], eval_sample_weight = [X_val[\"event_weight\"].to_numpy().flatten()],\n",
    "            callbacks=[pruning_callback])\n",
    "\n",
    "    # choose the highest auc score with event weight  \n",
    "    y_val_decisions = gbm.predict(X_val[training_vars], raw_score = True)\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_decisions, sample_weight = X_val['event_weight'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    return roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-24 12:42:33,904]\u001b[0m A new study created in memory with name: lightgbm_qgtagging\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.48805353449026784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48805353449026784\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.6649755830282306e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.6649755830282306e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5813995435791038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5813995435791038\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.030403280126677572, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.030403280126677572\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-24 12:42:58,873]\u001b[0m Trial 0 finished with value: 0.8147198216905984 and parameters: {'lambda_l1': 5.6649755830282306e-05, 'lambda_l2': 0.030403280126677572, 'num_leaves': 2, 'feature_fraction': 0.5813995435791038, 'bagging_fraction': 0.48805353449026784, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 0 with value: 0.8147198216905984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8111317002380557, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8111317002380557\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2883876209377052e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2883876209377052e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6515167086419769, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6515167086419769\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.72312200494449e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.72312200494449e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-24 12:44:39,977]\u001b[0m Trial 1 finished with value: 0.8303278482942958 and parameters: {'lambda_l1': 1.2883876209377052e-05, 'lambda_l2': 3.72312200494449e-05, 'num_leaves': 139, 'feature_fraction': 0.6515167086419769, 'bagging_fraction': 0.8111317002380557, 'bagging_freq': 2, 'min_child_samples': 89}. Best is trial 1 with value: 0.8303278482942958.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.4842321631571403, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4842321631571403\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.763958399884789e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.763958399884789e-08\n",
      "[LightGBM] [Warning] feature_fraction is set=0.735213897067451, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.735213897067451\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.010819509974097813, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.010819509974097813\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-24 12:44:42,207]\u001b[0m Trial 2 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 12:44:59,514]\u001b[0m Trial 3 finished with value: 0.5 and parameters: {'lambda_l1': 5.180291295699627, 'lambda_l2': 6.6193844201488494e-06, 'num_leaves': 178, 'feature_fraction': 0.9258334913776229, 'bagging_fraction': 0.9367639981023084, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 1 with value: 0.8303278482942958.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9747337180903012, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9747337180903012\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.376554594427989e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.376554594427989e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6526645750030313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6526645750030313\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8003547575557912, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8003547575557912\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-24 12:45:51,074]\u001b[0m Trial 4 finished with value: 0.8168065696641693 and parameters: {'lambda_l1': 3.376554594427989e-07, 'lambda_l2': 0.8003547575557912, 'num_leaves': 27, 'feature_fraction': 0.6526645750030313, 'bagging_fraction': 0.9747337180903012, 'bagging_freq': 4, 'min_child_samples': 71}. Best is trial 1 with value: 0.8303278482942958.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8500865889669804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8500865889669804\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.912588094940543e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.912588094940543e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4109729664065151, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4109729664065151\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.015083716080906013, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015083716080906013\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-24 12:46:59,092]\u001b[0m Trial 5 finished with value: 0.8272266212120318 and parameters: {'lambda_l1': 6.912588094940543e-06, 'lambda_l2': 0.015083716080906013, 'num_leaves': 214, 'feature_fraction': 0.4109729664065151, 'bagging_fraction': 0.8500865889669804, 'bagging_freq': 7, 'min_child_samples': 76}. Best is trial 1 with value: 0.8303278482942958.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9451573018558573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9451573018558573\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.341919070318744e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.341919070318744e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6687361157055431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6687361157055431\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12691529280491062, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12691529280491062\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-24 12:48:15,493]\u001b[0m Trial 6 finished with value: 0.825681903485009 and parameters: {'lambda_l1': 3.341919070318744e-06, 'lambda_l2': 0.12691529280491062, 'num_leaves': 28, 'feature_fraction': 0.6687361157055431, 'bagging_fraction': 0.9451573018558573, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 1 with value: 0.8303278482942958.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5593279956233357, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5593279956233357\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4799844388224288e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4799844388224288e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5269768696000354, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5269768696000354\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.493834966470408e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.493834966470408e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-24 12:48:20,507]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-01-24 12:49:14,686]\u001b[0m Trial 8 finished with value: 0.8282097133198034 and parameters: {'lambda_l1': 0.0014691239860705116, 'lambda_l2': 2.091978294467618e-07, 'num_leaves': 152, 'feature_fraction': 0.8198550160125587, 'bagging_fraction': 0.46140065729669555, 'bagging_freq': 3, 'min_child_samples': 71}. Best is trial 1 with value: 0.8303278482942958.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7089334672349852, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7089334672349852\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.340887446119036e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.340887446119036e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7982767871318732, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7982767871318732\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8156659603215856e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8156659603215856e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-24 12:50:39,189]\u001b[0m Trial 9 finished with value: 0.8302146549813526 and parameters: {'lambda_l1': 5.340887446119036e-05, 'lambda_l2': 2.8156659603215856e-08, 'num_leaves': 138, 'feature_fraction': 0.7982767871318732, 'bagging_fraction': 0.7089334672349852, 'bagging_freq': 7, 'min_child_samples': 61}. Best is trial 1 with value: 0.8303278482942958.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed=1)\n",
    "study = optuna.create_study(study_name=\"lightgbm_qgtagging\", direction=\"maximize\", sampler = sampler, pruner=optuna.pruners.HyperbandPruner())\n",
    "\n",
    "study.optimize(objective, n_trials=n_trails, n_jobs = 1)\n",
    "# n_jobs doesn't make tuning faster because it uses multi-threading.\n",
    "# https://optuna.readthedocs.io/en/stable/faq.html#multi-threading-parallelization-with-a-single-node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['small_dataset/study.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(study, study_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = joblib.load(\"study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda_l1': 1.2883876209377052e-05,\n",
       " 'lambda_l2': 3.72312200494449e-05,\n",
       " 'num_leaves': 139,\n",
       " 'feature_fraction': 0.6515167086419769,\n",
       " 'bagging_fraction': 0.8111317002380557,\n",
       " 'bagging_freq': 2,\n",
       " 'min_child_samples': 89}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8303278482942958"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the best params to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.505323\tvalid_0's auc: 0.830264\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result={}\n",
    "best_model = lgb.LGBMClassifier(**study.best_params)\n",
    "best_model.fit(X = X_train[training_vars], y = y_train, sample_weight=X_train[training_weight].to_numpy().flatten(),\n",
    "               eval_set = [(X_val[training_vars], y_val)], eval_sample_weight = [X_val[\"event_weight\"].to_numpy().flatten()],\n",
    "               eval_metric = ['binary_logloss', 'auc'], callbacks=[lgb.early_stopping(5), lgb.record_evaluation(eval_result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['small_dataset/eval_result.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, gbdt_filename)\n",
    "joblib.dump(eval_result, eval_result_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14e3b66b9136298b1438aa954b24fb6042eb4a7b64fe2e32b506f4a92d36ab42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
