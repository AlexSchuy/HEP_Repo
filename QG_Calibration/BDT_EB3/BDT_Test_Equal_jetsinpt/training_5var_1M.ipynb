{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import uproot \n",
    "import awkward as ak\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Dict, List \n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_vars = ['jet_pt', 'jet_eta', 'jet_nTracks', 'jet_trackWidth', 'jet_trackC1']\n",
    "all_vars = training_vars + ['total_weight', 'flatpt_weight']\n",
    "n_jets = 2_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_alljets_path = '../../samples/BDT_training/sample_2M_w_flatpt.pkl'\n",
    "with open(sample_alljets_path, 'rb') as f:\n",
    "    sample_2Mjets = pd.read_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_2Mjets.iloc[:, :-1]\n",
    "y = sample_2Mjets.iloc[:, -1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_dev,X_eval, y_dev,y_eval = train_test_split(X, y, test_size=0.1, random_state=456)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dev, y_dev, test_size=0.1/0.9, random_state=789)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m dt \u001b[39m=\u001b[39m DecisionTreeClassifier(max_depth\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,\n\u001b[1;32m      6\u001b[0m                             min_samples_leaf\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m,\n\u001b[1;32m      7\u001b[0m                             max_features\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlog2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m bdt \u001b[39m=\u001b[39m AdaBoostClassifier(dt,\n\u001b[1;32m      9\u001b[0m                          algorithm\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m                          n_estimators\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m,\n\u001b[1;32m     11\u001b[0m                          learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m bdt\u001b[39m.\u001b[39;49mfit(X_train[training_vars], y_train, sample_weight\u001b[39m=\u001b[39;49mX_train[\u001b[39m'\u001b[39;49m\u001b[39mflatpt_weight\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:506\u001b[0m, in \u001b[0;36mAdaBoostClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    501\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAlgorithm must be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    505\u001b[0m \u001b[39m# Fit\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:160\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    156\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m    158\u001b[0m \u001b[39mfor\u001b[39;00m iboost \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators):\n\u001b[1;32m    159\u001b[0m     \u001b[39m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     sample_weight, estimator_weight, estimator_error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost(\n\u001b[1;32m    161\u001b[0m         iboost, X, y, sample_weight, random_state\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Early termination\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:571\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[1;32m    570\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[0;32m--> 571\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:636\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_discrete\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[39m\"\"\"Implement a single boost using the SAMME discrete algorithm.\"\"\"\u001b[39;00m\n\u001b[1;32m    634\u001b[0m estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m--> 636\u001b[0m estimator\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m    638\u001b[0m y_predict \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mpredict(X)\n\u001b[1;32m    640\u001b[0m \u001b[39mif\u001b[39;00m iboost \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    940\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    970\u001b[0m         X,\n\u001b[1;32m    971\u001b[0m         y,\n\u001b[1;32m    972\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    973\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/sw/miniconda3/envs/ml/lib/python3.9/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5,\n",
    "                            min_samples_leaf=0.001,\n",
    "                            max_features=\"log2\")\n",
    "bdt = AdaBoostClassifier(dt,\n",
    "                         algorithm='SAMME',\n",
    "                         n_estimators=500,\n",
    "                         learning_rate=0.1)\n",
    "\n",
    "bdt.fit(X_train[training_vars], y_train, sample_weight=X_train['flatpt_weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = './BDT_5var_1M.model'\n",
    "pickle.dump(bdt, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_decisions = bdt.decision_function(X_test[training_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_gluon_id = np.where(y_test==1)[0]\n",
    "y_test_quark_id = np.where(y_test==0)[0]\n",
    "bins_scores = np.linspace(-1, 1, 50)\n",
    "plt.hist(y_test_decisions[y_test_gluon_id], weights=X_test.iloc[y_test_gluon_id, -1], bins= bins_scores, alpha=0.5, label='gluon'+f\"_num: {len(y_test_gluon_id)}\", color = 'blue') # add the weights! \n",
    "plt.hist(y_test_decisions[y_test_quark_id], weights=X_test.iloc[y_test_quark_id, -1], bins= bins_scores, alpha=0.5, label='quark'+f\"_num: {len(y_test_quark_id)}\", color = 'red')\n",
    "plt.legend(loc='upper left')\n",
    "plt.text(0.05, 0.75, f\"num: {len(X_test)}\", transform=plt.gca().transAxes)\n",
    "plt.xlabel(\"BDT Decision Function\")\n",
    "plt.ylabel(\"number of jets\")\n",
    "plt.title(r\"New Training with flat $p_{T}$\")\n",
    "plt.savefig(\"BDT_5var_1M.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def Draw_ROC_all(y, decisions, y_tmva, y_ntrk, X_weight, features, file_name):\n",
    "    # Compute ROC curve and area under the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y, decisions, sample_weight = X_weight)\n",
    "    fpr_tmva, tpr_tmva, thresholds_tmva = roc_curve(y, y_tmva, sample_weight = X_weight)\n",
    "    fpr_ntrk, tpr_ntrk, thresholds_ntrk =  roc_curve(y, y_ntrk, sample_weight = X_weight)\n",
    "\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_auc_tmva = auc(fpr_tmva, tpr_tmva)\n",
    "    roc_auc_ntrk = auc(fpr_ntrk, tpr_ntrk)\n",
    "\n",
    "\n",
    "    plt.plot(1-fpr, tpr, lw=1, label='ROC_NewTraining (area = %0.3f)'%(roc_auc))\n",
    "    plt.plot(1-fpr_tmva, tpr_tmva, lw=1, label='ROC_TMVA (area = %0.3f)'%(roc_auc_tmva))\n",
    "    plt.plot(1-fpr_ntrk, tpr_ntrk, lw=1, label='ROC_Ntrk (area = %0.3f)'%(roc_auc_ntrk))\n",
    "\n",
    "    plt.plot([0, 1], [1, 0], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC with features:{features}'+r\" flat $p_{T}$\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid()\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Draw_ROC_all(y_test, y_test_decisions, y_tmva=X_test['jet_trackBDT'] , y_ntrk=X_test['jet_nTracks'], X_weight=X_test['total_weight'], features=\"All\", file_name = 'BDT_ROC_5var_1M')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y_score in Pt bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_bins = np.linspace(-1, 1, 50)\n",
    "\n",
    "label_ptrange = np.array([500, 600, 800, 1000, 1200, 1500, 2000])\n",
    "pt_binned_jets_idx = np.digitize(X_test['jet_pt'], bins=label_ptrange)\n",
    "for i, pt in enumerate(label_ptrange[:-1]):\n",
    "    jets_at_pt_idx = np.where(pt_binned_jets_idx-1 == i)\n",
    "    jets_at_pt = X_test.iloc[jets_at_pt_idx]\n",
    "    y_test_at_pt = y_test.iloc[jets_at_pt_idx]\n",
    "    gluon_idx = np.where(y_test_at_pt ==1)[0]\n",
    "    quark_idx = np.where(y_test_at_pt ==0)[0]\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.hist(y_test_decisions[jets_at_pt_idx][quark_idx], weights=jets_at_pt.iloc[quark_idx, -1], bins =  bdt_bins, alpha = 0.5, label='Quark Jets', density = True)\n",
    "    ax.hist(y_test_decisions[jets_at_pt_idx][gluon_idx], weights=jets_at_pt.iloc[gluon_idx, -1], bins =  bdt_bins, alpha = 0.5, label='Gluon Jets', density = True)\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"{pt} - {label_ptrange[i+1]} GeV jets\")\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8bdd0311bdd426c87686682c9d205df6accd82833b0acc4f37e182f9e9921cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
